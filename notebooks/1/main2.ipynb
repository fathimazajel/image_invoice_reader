{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da2504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# SECTION 1: IMPORTS AND SETUP\n",
    "# ===============================\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# ===============================\n",
    "# SECTION 2: DATA EXTRACTION\n",
    "# ===============================\n",
    "# Paths and glob for CSV and JSON\n",
    "\n",
    "# Paths to the directories\n",
    "csv_folder = '/Users/fathimazajel/Documents/GitHub/image_invoice_reader/data/box'\n",
    "json_folder = '/Users/fathimazajel/Documents/GitHub/image_invoice_reader/data/key'\n",
    "\n",
    "# List all files\n",
    "csv_files = glob.glob(os.path.join(csv_folder, '*.csv'))\n",
    "json_files = glob.glob(os.path.join(json_folder, '*.json'))\n",
    "\n",
    "# Create a dictionary of JSON files\n",
    "json_file_dict = {os.path.splitext(os.path.basename(jf))[0]: jf for jf in json_files}\n",
    "\n",
    "# Initialize lists to hold texts and labels\n",
    "texts = []\n",
    "labels = []\n",
    "# Process each CSV file\n",
    "for csv_file in csv_files:\n",
    "    csv_filename_without_extension = os.path.splitext(os.path.basename(csv_file))[0]\n",
    "    \n",
    "    json_file = json_file_dict.get(csv_filename_without_extension)\n",
    "    if json_file:\n",
    "        # Load data\n",
    "        df_csv = pd.read_csv(csv_file, header=None, sep=\"\\t\")  # Adjust parameters if needed\n",
    "        \n",
    "        with open(json_file, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "        \n",
    "        # Extract and label data\n",
    "        for index, row in df_csv.iterrows():\n",
    "            if len(row) > 8:  # Make sure the row has at least 9 columns\n",
    "                text_segment = str(row[8]).strip()  # The ninth column contains the text\n",
    "        \n",
    "                # Simple method to match and label text segments\n",
    "                if text_segment in json_data[\"company\"]:\n",
    "                    labels.append(\"company\")\n",
    "                elif text_segment in json_data[\"date\"]:\n",
    "                    labels.append(\"date\")\n",
    "                elif text_segment in json_data[\"address\"]:\n",
    "                    labels.append(\"address\")\n",
    "                elif text_segment in json_data[\"total\"]:\n",
    "                    labels.append(\"total\")\n",
    "                else:\n",
    "                    labels.append(\"other\")\n",
    "                \n",
    "                texts.append(text_segment)\n",
    "            else:\n",
    "                print(f\"Row {index} in file {csv_file} does not have 9 columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2844e514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: openpyxl in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: et-xmlfile in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dd73916",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1707284056.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [2]\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install pandas openpyxl\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# SECTION 3: DATA CONVERSION\n",
    "# ===============================\n",
    "# Convert txt files to xls format\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Source and destination directories\n",
    "source_dir = \"/Users/fathimazajel/Documents/GitHub/image_invoice_reader/data/box\"\n",
    "dest_dir = \"/Users/fathimazajel/Documents/GitHub/image_invoice_reader/data/box2\"\n",
    "\n",
    "# Ensure destination directory exists\n",
    "os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "# List all .txt files in source directory\n",
    "txt_files = [f for f in os.listdir(source_dir) if f.endswith('.txt')]\n",
    "\n",
    "for txt_file in txt_files:\n",
    "    # Build the corresponding .xls filename\n",
    "    xls_file = os.path.splitext(txt_file)[0] + \".xls\"\n",
    "    \n",
    "    # Read each line from the txt file, split the data, and collect in a list\n",
    "    data_list = []\n",
    "    with open(os.path.join(source_dir, txt_file), 'r', encoding='utf-8') as infile:\n",
    "        for line in infile:\n",
    "            # Split by comma and extract columns and text\n",
    "            columns = line.strip().split(\",\")[:8]\n",
    "            text = \",\".join(line.strip().split(\",\")[8:])\n",
    "            data_list.append(columns + [text])\n",
    "\n",
    "    # Convert the data list to a DataFrame and write to Excel\n",
    "    df = pd.DataFrame(data_list, columns=[\"Column1\", \"Column2\", \"Column3\", \"Column4\", \"Column5\", \"Column6\", \"Column7\", \"Column8\", \"Text\"])\n",
    "    df.to_excel(os.path.join(dest_dir, xls_file), index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"Converted {len(txt_files)} .txt files to .xls in {dest_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "478149aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file '/Users/fathimazajel/Documents/GitHub/image_invoice_reader/data/box2/X00016469612.xls' has 44 rows and 9 columns.\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# SECTION 4: DATA VALIDATION\n",
    "# ===============================\n",
    "# Validate the data dimensions in xls files\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the .xls file\n",
    "xls_file_path = \"/Users/fathimazajel/Documents/GitHub/image_invoice_reader/data/box2/X00016469612.xls\"  # replace 'filename.xls' with the name of the file you want to check\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(xls_file_path, engine='openpyxl')\n",
    "\n",
    "# Get the dimensions\n",
    "num_rows, num_cols = df.shape\n",
    "\n",
    "print(f\"The file '{xls_file_path}' has {num_rows} rows and {num_cols} columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "056d2674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file /Users/fathimazajel/Documents/GitHub/image_invoice_reader/data/key/X51005663280.json does not contain the 'address' key.\n",
      "{'company': 'T.A.S LEISURE SDN BHD', 'date': '30 DEC 17', 'total': '102.40'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# SECTION 5: DATA LABELLING\n",
    "# ===============================\n",
    "# Extract and label data from XLS\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "\n",
    "xls_folder = '/Users/fathimazajel/Documents/GitHub/image_invoice_reader/data/box2'\n",
    "json_folder = '/Users/fathimazajel/Documents/GitHub/image_invoice_reader/data/key'\n",
    "\n",
    "xls_files = glob.glob(os.path.join(xls_folder, '*.xls'))\n",
    "json_files = glob.glob(os.path.join(json_folder, '*.json'))\n",
    "\n",
    "json_file_dict = {os.path.splitext(os.path.basename(jf))[0]: jf for jf in json_files}\n",
    "\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "for xls_file in xls_files:\n",
    "    xls_filename_without_extension = os.path.splitext(os.path.basename(xls_file))[0]\n",
    "    \n",
    "    json_file = json_file_dict.get(xls_filename_without_extension)\n",
    "    if json_file:\n",
    "        df_xls = pd.read_excel(xls_file, header=None)\n",
    "        \n",
    "        with open(json_file, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "        \n",
    "        # Check if 'address' is missing in the JSON data and print the content\n",
    "        if 'address' not in json_data:\n",
    "            print(f\"JSON file {json_file} does not contain the 'address' key.\")\n",
    "            print(json_data)\n",
    "            print(\"-\" * 50)  # Just for better visual separation\n",
    "        \n",
    "        # This assumes the last column in the xls file is the text\n",
    "        for _, row in df_xls.iterrows():\n",
    "            segment = str(row.iloc[-1])\n",
    "\n",
    "            # Basic matching for labels. This is very rudimentary and might need further refinement.\n",
    "            if 'company' in json_data and segment in json_data['company']:\n",
    "                label = \"company\"\n",
    "            elif 'date' in json_data and segment in json_data['date']:\n",
    "                label = \"date\"\n",
    "            elif 'address' in json_data and segment in json_data['address']:\n",
    "                label = \"address\"\n",
    "            elif 'total' in json_data and segment in json_data['total']:\n",
    "                label = \"total\"\n",
    "            else:\n",
    "                label = \"other\"\n",
    "\n",
    "            texts.append(segment)\n",
    "            labels.append(label)\n",
    "\n",
    "    else:\n",
    "        print(f\"No corresponding JSON file found for {xls_file}\")\n",
    "\n",
    "# At this point, texts and labels have your data labeled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8190f6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data segments have labels.\n",
      "There are 28421 data segments labeled as 'other'.\n",
      "Label distribution: {'other': 28421, 'address': 1844, 'company': 731, 'total': 1578, 'date': 1678}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. Check if the length of texts and labels lists are the same\n",
    "if len(texts) == len(labels):\n",
    "    print(\"All data segments have labels.\")\n",
    "else:\n",
    "    print(\"Mismatch between number of data segments and labels.\")\n",
    "\n",
    "# 2. Check for \"other\" labels\n",
    "other_count = labels.count(\"other\")\n",
    "if other_count > 0:\n",
    "    print(f\"There are {other_count} data segments labeled as 'other'.\")\n",
    "\n",
    "# 3. Verify the distribution of the labels\n",
    "label_distribution = {label: labels.count(label) for label in set(labels)}\n",
    "print(\"Label distribution:\", label_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "564dcab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (4.33.3)\n",
      "Requirement already satisfied: datasets in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (2.14.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: filelock in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: requests in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: multiprocess in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: pandas in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.4.2)\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: xxhash in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from async-timeout<5.0,>=4.0.0a3->aiohttp->datasets) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/fathimazajel/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc321aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# SECTION 6: MODEL PREPARATION AND TRAINING\n",
    "# ===============================\n",
    "# Tokenization and dataset preparation\n",
    "\n",
    "\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Tokenize the texts\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "train_encodings = tokenizer(texts, truncation=True, padding=True)\n",
    "\n",
    "# Convert labels from strings to integers\n",
    "label_dict = {\"company\": 0, \"date\": 1, \"address\": 2, \"total\": 3, \"other\": 4}\n",
    "labels = [label_dict[l] for l in labels]\n",
    "\n",
    "# Load into a dataset object\n",
    "dataset = load_dataset('pandas', data_files={'train': pd.DataFrame({'text': texts, 'labels': labels})})\n",
    "\n",
    "# Initialize model\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(label_dict))\n",
    "\n",
    "# Define training arguments and train\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    do_train=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps=10,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(\"./my_model\")\n",
    "tokenizer.save_pretrained(\"./my_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c943b3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b23593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba1ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6059e920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db47e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
